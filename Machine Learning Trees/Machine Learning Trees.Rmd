---
title: "Machine Learning Trees"
author: "Ken Harmon"
date: "`r format(Sys.time(), '%Y %B %d')`"
output:
  html_document:  
    keep_md: true
    code_folding: hide
    fig_height: 6
    fig_width: 12
    fig_align: 'center'
editor_options: 
  chunk_output_type: console
---

# {.tabset .tabset-fade}

```{r, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

```{r load_libraries, include=FALSE}
# Use this R-Chunk to load all your libraries!
pacman::p_load(tidyverse, DT, rpart, DMwR, caret, rpart.plot, rattle, Metrics)
theme_set(theme_bw())
confusionMatrix <- caret::confusionMatrix
```

```{r swd, eval=FALSE, echo=FALSE}
# this is set to not run during the knit process
# this sets the working directory to the file location
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
```

## Classification Trees

Build a classification tree
Let's get started and build our first classification tree. A classification tree is a decision tree that performs a classification (vs regression) task.

You will train a decision tree model to understand which loan applications are at higher risk of default using a subset of the German Credit Dataset. The response variable, called "default", indicates whether the loan went into a default or not, which means this is a binary classification problem (there are just two classes).

You will use the rpart package to fit the decision tree and the rpart.plot package to visualize the tree.

Instructions
100 XP
The data frame creditsub is in the workspace. This data frame is a subset of the original German Credit Dataset, which we will use to train our first classification tree model.

Take a look at the data using the str() function.
In R, formulas are used to model the response as a function of some set of predictors, so the formula here is default ~ ., which means use all columns (except the response column) as predictors.
Fit the classification decision tree using the rpart() function from the rpart package. In the rpart() function, note that you'll also have to provide the training data frame.
Using the model object that you create, plot the decision tree model using the rpart.plot() function from the rpart.plot package.


```{r bct}
creditsub <- read.csv("creditsub.csv")

# Look at the data
str(creditsub)

# Create the model
credit_model <- rpart(formula = default ~ ., data = creditsub, method = "class")

# Display the results
rpart.plot(x = credit_model, yesno = 2, type = 0, extra = 0)
```

Train/test split
For this exercise, you'll randomly split the German Credit Dataset into two pieces: a training set (80%) called credit_train and a test set (20%) that we will call credit_test. We'll use these two sets throughout the chapter.

Instructions
100 XP
The credit data frame is loaded into the workspace.

Define n, the number of rows in the credit data frame.
Define n_train to be ~80% of n.
Set a seed (for reproducibility) and then sample n_train rows to define the set of training set indices.
Using row indices, subset the credit data frame to create two new datasets: credit_train and credit_test

```{r tts}
credit <- read.csv("credit.csv")

# Total number of rows in the credit data frame
n <- nrow(credit)

# Number of rows for the training set (80% of the dataset)
n_train <- round(.8 * n) 

# Create a vector of indices which is an 80% random sample
set.seed(123)
train_indices <- sample(1:n, n_train)

# Subset the credit data frame to training indices only
credit_train <- credit[train_indices, ]  
  
# Exclude the training indices to create the test set
credit_test <- credit[-train_indices, ] 
```

Train a classification tree model
In this exercise, you will train a model on the newly created training set and print the model object to get a sense of the results.

```{r tctm}
# Train the model (to predict 'default')
credit_model <- rpart(formula = default ~ ., data = credit_train, method = "class")

# Look at the model output                      
print(credit_model)
```

Compute confusion matrix
As discussed in the previous video, there are a number of different metrics by which you can measure the performance of a classification model. In this exercise, we will evaluate the performance of the model using test set classification error. A confusion matrix is a convenient way to examine the per-class error rates for all classes at once.

The confusionMatrix() function from the caret package prints both the confusion matrix and a number of other useful classification metrics such as "Accuracy" (fraction of correctly classified instances).

The caret package has been loaded for you.

Instructions
100 XP
Generate class predictions for the credit_test data frame using the credit_model object.
Using the caret::confusionMatrix() function, compute the confusion matrix for the test set.

```{r ccm}
# Generate predicted classes using the model object
class_prediction <- predict(object = credit_model,  
                        newdata = credit_test,   
                        type = "class")  
                            
# Calculate the confusion matrix for the test set
confusionMatrix(data = class_prediction,       
                reference = credit_test$default) 
```

Compare models with a different splitting criterion
Train two models that use a different splitting criterion and use the validation set to choose a "best" model from this group. To do this you'll use the parms argument of the rpart() function. This argument takes a named list that contains values of different parameters you can use to change how the model is trained. Set the parameter split to control the splitting criterion.

Instructions
100 XP
The datasets credit_test and credit_train have already been loaded for you.

Train a model, splitting the tree based on gini index.
Train a model, splitting the tree based on information index.
Generate predictions on the validation set using both models.
Classification error is the fraction of incorrectly classified instances. Compute and compare the test set classification error of the two models by using the ce() function.

```{r cmdsc}
# Train a gini-based model
credit_model1 <- rpart(formula = default ~ ., 
                       data = credit_train, 
                       method = "class",
                       parms = list(split = "gini"))

# Train an information-based model
credit_model2 <- rpart(formula = default ~ ., 
                       data = credit_train, 
                       method = "class",
                       parms = list(split = "information"))

# Generate predictions on the validation set using the gini model
pred1 <- predict(object = credit_model1, 
             newdata = credit_test,
             type = "class")  

# Generate predictions on the validation set using the information model
pred2 <- predict(object = credit_model2, 
             newdata = credit_test,
             type = "class")

# Compare classification error
ce(actual = credit_test$default, 
   predicted = pred1)
ce(actual = credit_test$default, 
   predicted = pred2) 
```

## Regression Trees

Split the data
These examples will use a subset of the Student Performance Dataset from UCI ML Dataset Repository.

The goal of this exercise is to predict a student's final Mathematics grade based on the following variables: sex, age, address, studytime (weekly study time), schoolsup (extra educational support), famsup (family educational support), paid (extra paid classes within the course subject) and absences.

The response is final_grade (numeric: from 0 to 20, output target).

After initial exploration, split the data into training, validation, and test sets. In this chapter, we will introduce the idea of a validation set, which can be used to select a "best" model from a set of competing models.

In Chapter 1, we demonstrated a simple way to split the data into two pieces using the sample() function. In this exercise, we will take a slightly different approach to splitting the data that allows us to split the data into more than two parts (here, we want three: train, validation, test). We still use the sample() function, but instead of sampling the indices themselves, we will assign each row to either the training, validation or test sets according to a probability distribution.

The dataset grade is already in your workspace.

Instructions
100 XP
Take a look at the data using the str() function.
Set a seed (for reproducibility) and then sample n_train rows to define the set of training set indices.
Draw a sample of size nrow(grade) from the number 1 to 3 (with replacement). You want approximately 70% of the sample to be 1 and the remaining 30% to be equally split between 2 and 3.
Subset grade using the sample you just drew so that indices with the value 1 are in grade_train, indices with the value 2 are in grade_valid, and indices with 3 are in grade_test.

```{r std}
grade <- read.csv("grades.csv")

# Look at the data
str(grade)

# Set seed and create assignment
set.seed(1)
assignment <- sample(1:3, size = nrow(grade), prob = c(.7,.15,.15), replace = TRUE)

# Create a train, validation and tests from the original data frame 
grade_train <- grade[assignment == 1, ]    # subset grade to training indices only
grade_valid <- grade[assignment == 2, ]  # subset grade to validation indices only
grade_test <- grade[assignment == 3, ]   # subset grade to test indices only
```

Train a regression tree model
In this exercise, we will use the grade_train dataset to fit a regression tree using rpart() and visualize it using rpart.plot(). A regression tree plot looks identical to a classification tree plot, with the exception that there will be numeric values in the leaf nodes instead of predicted classes.

This is very similar to what we did previously in Chapter 1. When fitting a classification tree, we use method = "class", however, when fitting a regression tree, we need to set method = "anova". By default, the rpart() function will make an intelligent guess as to what the method value should be based on the data type of your response column, but it's recommened that you explictly set the method for reproducibility reasons (since the auto-guesser may change in the future).

The grade_train training set is loaded into the workspace.

Instructions
100 XP
Using the grade_train dataframe and the given formula, train a regresion tree.
Look at the model output by printing the model object.
Plot the decision tree using rpart.plot().

```{r trtm}
# Train the model
grade_model <- rpart(formula = final_grade ~ ., 
                     data = grade_train,
                     method = "anova")

# Look at the model output                      
print(grade_model)

# Plot the tree model
rpart.plot(x = grade_model, yesno = 2, type = 0, extra = 0)
```

Evaluate a regression tree model
Predict the final grade for all students in the test set. The grade is on a 0-20 scale. Evaluate the model based on test set RMSE (Root Mean Squared Error). RMSE tells us approximately how far away our predictions are from the true values.

Instructions
100 XP
First generate predictions on the grade_test data frame using the grade_model object.
After generating test set predictions, use the rmse() function from the Metrics package to compute test set RMSE.

```{r ertm}
# Generate predictions on a test set
pred <- predict(object = grade_model,   # model object 
                newdata = grade_test)  # test dataset

# Compute the RMSE
rmse(actual = grade_test$final_grade, 
     predicted = pred)
```

Tuning the model
Tune (or "trim") the model using the prune() function by finding the best "CP" value (CP stands for "Complexity Parameter").

Instructions
100 XP
Print the CP Table, a matrix of information on the optimal prunings (based on CP).
Retrieve the optimal CP value; the value for CP which minimizes cross-validated error of the model.
Use the prune() function trim the tree, snipping off the least important splits, based on CP.







